"""
í…ìŠ¤íŠ¸ ì„ë² ë”© ìœ í‹¸ë¦¬í‹°
- TF-IDF Vectorizerë¥¼ ì‚¬ìš©í•˜ì—¬ ë¦¬ë·° í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
- í•™ìŠµê³¼ ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œ ê³µí†µìœ¼ë¡œ ì‚¬ìš©
"""

import pickle
import numpy as np
import os
import logging

logger = logging.getLogger(__name__)

class TextEmbeddingService:
    """í…ìŠ¤íŠ¸ ì„ë² ë”© ì„œë¹„ìŠ¤ í´ë˜ìŠ¤"""
    
    def __init__(self, vectorizer_path='models/tfidf_vectorizer.pkl'):
        """
        Args:
            vectorizer_path: TF-IDF Vectorizer íŒŒì¼ ê²½ë¡œ
        """
        self.vectorizer_path = vectorizer_path
        self.vectorizer = None
        
    def load_vectorizer(self):
        """Vectorizer ë¡œë”© (ë¡œì»¬ -> HuggingFace ìˆœì„œë¡œ ì‹œë„)"""
        # 1. ë¡œì»¬ ê²½ë¡œ í™•ì¸
        if os.path.exists(self.vectorizer_path):
            logger.info(f"[Text Embedding] ë¡œì»¬ íŒŒì¼ ì‚¬ìš©: {self.vectorizer_path}")
            with open(self.vectorizer_path, 'rb') as f:
                self.vectorizer = pickle.load(f)
            logger.info(f"[Text Embedding] Vectorizer ë¡œë”© ì™„ë£Œ (ì–´íœ˜ í¬ê¸°: {len(self.vectorizer.vocabulary_)})")
            return True
        
        # 2. HuggingFaceì—ì„œ ë‹¤ìš´ë¡œë“œ ì‹œë„
        try:
            from model_loader import download_model_file
            logger.info("[Text Embedding] HuggingFaceì—ì„œ ë‹¤ìš´ë¡œë“œ ì‹œë„...")
            
            # HuggingFaceì—ëŠ” tfidf_vectorizer_309d.pklë¡œ ì €ì¥ë˜ì–´ ìˆìŒ
            downloaded_path = download_model_file("tfidf_vectorizer_309d.pkl")
            
            with open(downloaded_path, 'rb') as f:
                self.vectorizer = pickle.load(f)
            
            logger.info(f"[Text Embedding] HuggingFaceì—ì„œ ë¡œë”© ì™„ë£Œ (ì–´íœ˜ í¬ê¸°: {len(self.vectorizer.vocabulary_)})")
            return True
            
        except Exception as e:
            logger.error(f"[Text Embedding] HuggingFace ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise FileNotFoundError(f"Vectorizer íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.vectorizer_path}")
    
    def transform_text(self, text):
        """
        ë‹¨ì¼ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
        
        Args:
            text: ë¦¬ë·° í…ìŠ¤íŠ¸ (str)
            
        Returns:
            embedding: 100ì°¨ì› ë²¡í„° (numpy array)
        """
        import time
        import logging
        
        logger = logging.getLogger(__name__)
        embedding_start = time.time()
        
        if self.vectorizer is None:
            raise ValueError("Vectorizerê°€ ë¡œë”©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_vectorizer()ë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
        
        # í…ìŠ¤íŠ¸ê°€ Noneì´ê±°ë‚˜ ë¹ˆ ë¬¸ìì—´ì´ë©´ 0 ë²¡í„° ë°˜í™˜
        if not text or text.strip() == '':
            logger.info(f"ğŸ“Š [Text Embedding] ë¹ˆ í…ìŠ¤íŠ¸ - 0 ë²¡í„° ë°˜í™˜")
            return np.zeros(100, dtype=np.float32)
        
        logger.info(f"ğŸ“Š [Text Embedding] ì‹œì‘ (í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)}ì)")
        
        # TF-IDF ë³€í™˜
        tfidf_start = time.time()
        tfidf_vector = self.vectorizer.transform([text])
        tfidf_time = time.time() - tfidf_start
        logger.info(f"  â±ï¸  TF-IDF ë³€í™˜: {tfidf_time:.3f}s")
        
        # Dense arrayë¡œ ë³€í™˜
        dense_start = time.time()
        embedding = tfidf_vector.toarray()[0].astype(np.float32)
        dense_time = time.time() - dense_start
        logger.info(f"  â±ï¸  Dense ë³€í™˜: {dense_time:.3f}s")
        
        total_time = time.time() - embedding_start
        logger.info(f"âœ… [Text Embedding] ì™„ë£Œ - {total_time:.3f}s")
        
        return embedding
    
    def transform_texts(self, texts):
        """
        ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
        
        Args:
            texts: ë¦¬ë·° í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ (list of str)
            
        Returns:
            embeddings: (N, 100) í˜•íƒœì˜ numpy array
        """
        if self.vectorizer is None:
            raise ValueError("Vectorizerê°€ ë¡œë”©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_vectorizer()ë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
        
        # ë¹ˆ í…ìŠ¤íŠ¸ ì²˜ë¦¬
        processed_texts = [text if text and text.strip() else '' for text in texts]
        
        # TF-IDF ë³€í™˜
        tfidf_matrix = self.vectorizer.transform(processed_texts)
        
        # Dense arrayë¡œ ë³€í™˜
        embeddings = tfidf_matrix.toarray().astype(np.float32)
        
        return embeddings
    
    def get_average_embedding(self, texts):
        """
        ì—¬ëŸ¬ í…ìŠ¤íŠ¸ì˜ í‰ê·  ì„ë² ë”© ê³„ì‚°
        
        Args:
            texts: ë¦¬ë·° í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ (list of str)
            
        Returns:
            avg_embedding: 100ì°¨ì› í‰ê·  ë²¡í„° (numpy array)
        """
        if not texts or len(texts) == 0:
            return np.zeros(100, dtype=np.float32)
        
        embeddings = self.transform_texts(texts)
        avg_embedding = embeddings.mean(axis=0)
        
        return avg_embedding

# ì „ì—­ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
_text_embedding_service = None

def get_text_embedding_service():
    """í…ìŠ¤íŠ¸ ì„ë² ë”© ì„œë¹„ìŠ¤ ì‹±ê¸€í†¤"""
    global _text_embedding_service
    if _text_embedding_service is None:
        _text_embedding_service = TextEmbeddingService()
        _text_embedding_service.load_vectorizer()
    return _text_embedding_service









