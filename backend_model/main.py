"""
Tier 3: Model API Server
DeepFMê³¼ Multi-Tower ëª¨ë¸ì„ ì‚¬ìš©í•œ ë³„ì  ì˜ˆì¸¡ API
"""

import sys
import os
from pathlib import Path

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python pathì— ì¶”ê°€
current_dir = Path(__file__).parent
if str(current_dir) not in sys.path:
    sys.path.insert(0, str(current_dir))

from fastapi import FastAPI, HTTPException, status
from fastapi.middleware.cors import CORSMiddleware
import logging
from contextlib import asynccontextmanager

from prediction_service_309d import get_prediction_service
from absa_service import get_absa_service
from pydantic import BaseModel
from typing import Optional, List

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ì˜ˆì¸¡ ìš”ì²­/ì‘ë‹µ ìŠ¤í‚¤ë§ˆ
class PredictRatingRequest(BaseModel):
    """ë³„ì  ì˜ˆì¸¡ ìš”ì²­"""
    user_data: dict
    business_data: dict

class PredictRatingResponse(BaseModel):
    """ë³„ì  ì˜ˆì¸¡ ì‘ë‹µ"""
    deepfm_rating: float
    multitower_rating: Optional[float]  # Multi-Tower ì‚¬ìš© ë¶ˆê°€ ì‹œ None
    ensemble_rating: float
    confidence: float

class AnalyzeReviewRequest(BaseModel):
    """ë¦¬ë·° ë¶„ì„ ìš”ì²­"""
    text: str

class AnalyzeReviewResponse(BaseModel):
    """ë¦¬ë·° ë¶„ì„ ì‘ë‹µ"""
    absa_features: dict  # 51ê°œ aspect-sentiment í™•ë¥ 
    text_embedding: List[float]  # 100ì°¨ì› í…ìŠ¤íŠ¸ ì„ë² ë”©

# FastAPI ì•± ìƒëª…ì£¼ê¸° ê´€ë¦¬
@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì•± ì‹œì‘/ì¢…ë£Œ ì‹œ ì‹¤í–‰"""
    # Startup
    logger.info("Starting Model API Server...")
    try:
        # ì˜ˆì¸¡ ì„œë¹„ìŠ¤ ë¡œë”©
        pred_service = get_prediction_service()
        logger.info("Prediction Service loaded!")
        
        # ABSA ì„œë¹„ìŠ¤ ë¡œë”©
        absa_service = get_absa_service()
        logger.info("ABSA Service loaded!")
        
        logger.info("Model API Server started successfully!")
    except Exception as e:
        logger.error(f"Failed to start server: {e}")
        raise
    
    yield
    
    # Shutdown
    logger.info("Shutting down Model API Server...")

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="DeepFM & Multi-Tower Rating Prediction API",
    description="Rating prediction API using DeepFM and Multi-Tower models",
    version="1.0.0",
    lifespan=lifespan
)

# CORS ì„¤ì • (ê°œë°œ í™˜ê²½ìš©)
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:8000",  # ë¡œì»¬ Web Backend
        "https://backendweb-production-7b6c.up.railway.app",  # í”„ë¡œë•ì…˜
    ],  # í”„ë¡œë•ì…˜ì—ì„œëŠ” íŠ¹ì • ë„ë©”ì¸ìœ¼ë¡œ ì œí•œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/", tags=["Root"])
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "message": "DeepFM & Multi-Tower Rating Prediction API",
        "version": "1.0.0",
        "docs": "/docs"
    }

@app.get("/health", tags=["Health"])
async def health_check():
    """Health check ì—”ë“œí¬ì¸íŠ¸"""
    try:
        pred_service = get_prediction_service()
        absa_service = get_absa_service()
        return {
            "status": "healthy",
            "deepfm_loaded": pred_service.deepfm_model is not None,
            "multitower_loaded": pred_service.multitower_model is not None,
            "absa_loaded": absa_service.model is not None
        }
    except Exception as e:
        return {
            "status": "unhealthy",
            "error": str(e)
        }

@app.post("/predict_rating", response_model=PredictRatingResponse, tags=["Prediction"])
async def predict_rating(request: PredictRatingRequest):
    """
    ë³„ì  ì˜ˆì¸¡ ì—”ë“œí¬ì¸íŠ¸
    
    DeepFMê³¼ Multi-Tower ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìê°€ íŠ¹ì • ë¹„ì¦ˆë‹ˆìŠ¤ì— ë§¤ê¸¸ ë³„ì ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
    """
    # ìš”ì²­ ë¡œê·¸ëŠ” ë””ë²„ê·¸ ëª¨ë“œì—ì„œë§Œ ì¶œë ¥ (ë¡œê·¸ ê³¼ë‹¤ ë°©ì§€)
    if os.getenv("DEBUG_PREDICTION", "false").lower() == "true":
        logger.debug(f"Rating prediction request")
    
    try:
        pred_service = get_prediction_service()
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        result = pred_service.predict_rating(
            user_data=request.user_data,
            business_data=request.business_data
        )
        
        # ì˜ˆì¸¡ ê²°ê³¼ ë¡œê·¸ëŠ” ë””ë²„ê·¸ ëª¨ë“œì—ì„œë§Œ ì¶œë ¥ (ë¡œê·¸ ê³¼ë‹¤ ë°©ì§€)
        if os.getenv("DEBUG_PREDICTION", "false").lower() == "true":
            logger.debug(f"Prediction: DeepFM={result['deepfm_rating']}, MT={result['multitower_rating']}, Ensemble={result['ensemble_rating']}")
        
        return PredictRatingResponse(**result)
        
    except Exception as e:
        logger.error(f"Error in rating prediction: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to predict rating: {str(e)}"
        )

@app.post("/analyze_review", response_model=AnalyzeReviewResponse, tags=["ABSA"])
async def analyze_review(request: AnalyzeReviewRequest):
    """
    ë¦¬ë·° ë¶„ì„ ì—”ë“œí¬ì¸íŠ¸
    
    ë¦¬ë·° í…ìŠ¤íŠ¸ë¥¼ ë°›ì•„ì„œ ABSA ë¶„ì„ ë° í…ìŠ¤íŠ¸ ì„ë² ë”©ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    - ABSA: 51ê°œ aspect-sentiment í™•ë¥  (ì˜ˆ: ë§›_ê¸ì •, ì„œë¹„ìŠ¤_ë¶€ì • ë“±)
    - í…ìŠ¤íŠ¸ ì„ë² ë”©: TF-IDF ê¸°ë°˜ 100ì°¨ì› ë²¡í„°
    """
    import time
    
    endpoint_start = time.time()
    text_sample = request.text[:50] + "..." if len(request.text) > 50 else request.text
    logger.info(f"ğŸ“¥ [ABSA Endpoint] ìš”ì²­ ì‹œì‘ (í…ìŠ¤íŠ¸ ê¸¸ì´: {len(request.text)}ì)")
    logger.info(f"   í…ìŠ¤íŠ¸ ìƒ˜í”Œ: \"{text_sample}\"")
    
    try:
        absa_service = get_absa_service()
        pred_service = get_prediction_service()
        
        # Step 1: ABSA ë¶„ì„
        step1_start = time.time()
        absa_features = absa_service.analyze_review(request.text)
        step1_time = time.time() - step1_start
        logger.info(f"  â±ï¸  Step 1: ABSA ë¶„ì„ - {step1_time:.2f}s ({len(absa_features)} features)")
        
        # Step 2: í…ìŠ¤íŠ¸ ì„ë² ë”©
        step2_start = time.time()
        if pred_service.text_embedding_service is not None:
            text_embedding = pred_service.text_embedding_service.transform_text(request.text)
            text_embedding_list = text_embedding.tolist()
        else:
            # í…ìŠ¤íŠ¸ ì„ë² ë”© ì„œë¹„ìŠ¤ ì—†ìœ¼ë©´ 0 ë²¡í„°
            text_embedding_list = [0.0] * 100
        step2_time = time.time() - step2_start
        logger.info(f"  â±ï¸  Step 2: í…ìŠ¤íŠ¸ ì„ë² ë”© - {step2_time:.3f}s ({len(text_embedding_list)} dims)")
        
        # Step 3: ì‘ë‹µ ìƒì„±
        step3_start = time.time()
        response = AnalyzeReviewResponse(
            absa_features=absa_features,
            text_embedding=text_embedding_list
        )
        step3_time = time.time() - step3_start
        logger.info(f"  â±ï¸  Step 3: ì‘ë‹µ ìƒì„± - {step3_time:.3f}s")
        
        # ì „ì²´ ì†Œìš” ì‹œê°„
        total_time = time.time() - endpoint_start
        logger.info(f"âœ… [ABSA Endpoint] ì™„ë£Œ - ì´ ì†Œìš”: {total_time:.2f}s")
        
        return response
        
    except Exception as e:
        total_time = time.time() - endpoint_start
        logger.error(f"âŒ [ABSA Endpoint] ì‹¤íŒ¨ after {total_time:.2f}s: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to analyze review: {str(e)}"
        )

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8001)

