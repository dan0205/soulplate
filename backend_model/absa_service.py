"""
ABSA (Aspect-Based Sentiment Analysis) ì„œë¹„ìŠ¤
- BERT ê¸°ë°˜ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë¦¬ë·° í…ìŠ¤íŠ¸ ë¶„ì„
- 17ê°œ aspect Ã— 3ê°œ sentiment = 51ê°œ í´ë˜ìŠ¤ ì˜ˆì¸¡
"""

import torch
from transformers import BertForSequenceClassification, BertTokenizer
import numpy as np
import os
import json
import logging
from model_loader import ensure_absa_model

logger = logging.getLogger(__name__)


class ABSAService:
    """ABSA ë¶„ì„ ì„œë¹„ìŠ¤ í´ë˜ìŠ¤"""
    
    def __init__(self, model_path='models/absa'):
        """
        Args:
            model_path: ABSA ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
        """
        self.model_path = model_path
        self.model = None
        self.tokenizer = None
        self.id2label = None
        self.device = None
        
    def load_model(self):
        """ABSA ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë”© (HuggingFace Hubì—ì„œ ìë™ ë‹¤ìš´ë¡œë“œ)"""
        print(f"[ABSA] ëª¨ë¸ ë¡œë”© ì¤‘... ({self.model_path})")
        
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"[ABSA] ë””ë°”ì´ìŠ¤: {self.device}")
        if torch.cuda.is_available():
            print(f"[ABSA] GPU: {torch.cuda.get_device_name(0)}")
        
        # HuggingFaceì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œë„
        logger.info("ABSA ëª¨ë¸ HuggingFaceì—ì„œ ë‹¤ìš´ë¡œë“œ ì‹œë„...")
        hf_model_path = ensure_absa_model(self.model_path)
        actual_model_path = hf_model_path if hf_model_path else self.model_path
        
        if not os.path.exists(actual_model_path):
            raise FileNotFoundError(f"ABSA ëª¨ë¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {actual_model_path}")
        
        print(f"[ABSA] ëª¨ë¸ ê²½ë¡œ: {actual_model_path}")
        
        # ëª¨ë¸ ë¡œë”©
        self.model = BertForSequenceClassification.from_pretrained(actual_model_path)
        self.model.to(self.device)
        self.model.eval()
        
        # í† í¬ë‚˜ì´ì € ë¡œë”©
        self.tokenizer = BertTokenizer.from_pretrained(actual_model_path)
        
        # Label ì •ë³´ ë¡œë”©
        config_path = os.path.join(actual_model_path, "config.json")
        with open(config_path, "r", encoding="utf-8") as f:
            config = json.load(f)
        self.id2label = config["id2label"]
        
        print(f"[ABSA] ëª¨ë¸ ë¡œë”© ì™„ë£Œ ({len(self.id2label)}ê°œ í´ë˜ìŠ¤)")
        return True
    
    def analyze_review(self, text):
        """
        ë‹¨ì¼ ë¦¬ë·° í…ìŠ¤íŠ¸ ABSA ë¶„ì„
        
        Args:
            text: ë¦¬ë·° í…ìŠ¤íŠ¸ (str)
            
        Returns:
            dict: aspect-sentimentë³„ í™•ë¥ ê°’
                ì˜ˆ: {"ë§›_ê¸ì •": 0.95, "ë§›_ë¶€ì •": 0.02, "ë§›_ì¤‘ë¦½": 0.03, ...}
        """
        import time
        
        service_start = time.time()
        text_sample = text[:30] + "..." if len(text) > 30 else text
        logger.info(f"ğŸ” [ABSA Service] ë¶„ì„ ì‹œì‘ (í…ìŠ¤íŠ¸: \"{text_sample}\")")
        
        if self.model is None or self.tokenizer is None:
            raise ValueError("ëª¨ë¸ì´ ë¡œë”©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_model()ì„ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
        
        # í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìœ¼ë©´ ì¤‘ë¦½ ê°’ ë°˜í™˜
        if not text or text.strip() == '':
            logger.info(f"  âš ï¸  ë¹ˆ í…ìŠ¤íŠ¸ - ì¤‘ë¦½ê°’ ë°˜í™˜")
            return self._get_neutral_absa()
        
        # ë‹¨ê³„ 1: í† í¬ë‚˜ì´ì§•
        tokenize_start = time.time()
        inputs = self.tokenizer(
            text,
            return_tensors="pt",
            max_length=512,
            truncation=True,
            padding=True
        ).to(self.device)
        tokenize_time = time.time() - tokenize_start
        logger.info(f"  â±ï¸  í† í¬ë‚˜ì´ì§•: {tokenize_time:.3f}s")
        
        # ë‹¨ê³„ 2: ëª¨ë¸ ì¶”ë¡  (BERT) - ê°€ì¥ ì¤‘ìš”í•œ ì¸¡ì • ì§€ì !
        inference_start = time.time()
        with torch.no_grad():
            outputs = self.model(**inputs)
            logits = outputs.logits
        inference_time = time.time() - inference_start
        logger.info(f"  â±ï¸  ëª¨ë¸ ì¶”ë¡  (BERT): {inference_time:.3f}s âš ï¸ í•µì‹¬ ì§€ì !")
        
        # ë‹¨ê³„ 3: í›„ì²˜ë¦¬ (sigmoid)
        postprocess_start = time.time()
        probs = torch.sigmoid(logits)
        postprocess_time = time.time() - postprocess_start
        logger.info(f"  â±ï¸  í›„ì²˜ë¦¬ (sigmoid): {postprocess_time:.3f}s")
        
        # ë‹¨ê³„ 4: ê²°ê³¼ ë³€í™˜ (dict)
        convert_start = time.time()
        probs_array = probs.cpu().numpy()[0]
        absa_dict = {}
        
        for i, prob in enumerate(probs_array):
            label = self.id2label[str(i)]
            absa_dict[label] = float(prob)
        convert_time = time.time() - convert_start
        logger.info(f"  â±ï¸  ê²°ê³¼ ë³€í™˜ (dict): {convert_time:.3f}s")
        
        # ì „ì²´ ì†Œìš” ì‹œê°„
        total_time = time.time() - service_start
        logger.info(f"âœ… [ABSA Service] ì™„ë£Œ - ì´ ì†Œìš”: {total_time:.3f}s")
        
        return absa_dict
    
    def _get_neutral_absa(self):
        """ë¹ˆ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì¤‘ë¦½ ABSA ë°˜í™˜"""
        neutral_dict = {}
        for i in range(len(self.id2label)):
            label = self.id2label[str(i)]
            # ê¸ì •/ë¶€ì •ì€ ë‚®ê²Œ, ì¤‘ë¦½ì€ ë†’ê²Œ
            if "_ì¤‘ë¦½" in label:
                neutral_dict[label] = 0.7
            else:
                neutral_dict[label] = 0.15
        return neutral_dict
    
    def analyze_batch(self, texts, batch_size=32):
        """
        ë°°ì¹˜ ë‹¨ìœ„ë¡œ ABSA ë¶„ì„ (ë‹¤ì¤‘ ë¦¬ë·° ì²˜ë¦¬)
        
        Args:
            texts: ë¦¬ë·° í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ (list of str)
            batch_size: ë°°ì¹˜ í¬ê¸°
            
        Returns:
            list of dict: ê° í…ìŠ¤íŠ¸ì— ëŒ€í•œ ABSA ê²°ê³¼
        """
        if self.model is None or self.tokenizer is None:
            raise ValueError("ëª¨ë¸ì´ ë¡œë”©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_model()ì„ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
        
        results = []
        
        for i in range(0, len(texts), batch_size):
            batch_texts = texts[i:i+batch_size]
            
            # í† í¬ë‚˜ì´ì§•
            inputs = self.tokenizer(
                batch_texts,
                return_tensors="pt",
                max_length=512,
                truncation=True,
                padding=True
            ).to(self.device)
            
            # ì¶”ë¡ 
            with torch.no_grad():
                outputs = self.model(**inputs)
                logits = outputs.logits
                probs = torch.sigmoid(logits)
            
            # ê²°ê³¼ ë³€í™˜
            probs_array = probs.cpu().numpy()
            
            for prob_row in probs_array:
                absa_dict = {}
                for j, prob in enumerate(prob_row):
                    label = self.id2label[str(j)]
                    absa_dict[label] = float(prob)
                results.append(absa_dict)
        
        return results


# ì „ì—­ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤)
_absa_service = None


def get_absa_service():
    """ABSA ì„œë¹„ìŠ¤ ì‹±ê¸€í†¤"""
    global _absa_service
    if _absa_service is None:
        _absa_service = ABSAService()
        _absa_service.load_model()
    return _absa_service



