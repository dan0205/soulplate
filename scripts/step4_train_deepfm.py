"""
Step 4: DeepFM ëª¨ë¸ í•™ìŠµ (ì½”ë©ìš©)
- FM Layer + Deep Layer
- MSE Loss, RMSE Metric
- Batch Size: 512, Epochs: 20
- Google Driveì—ì„œ ë°ì´í„° ë¡œë”©
"""

import sys
import os

# ì½”ë© í™˜ê²½ ì²´í¬ ë° Google Drive ë§ˆìš´íŠ¸
try:
    from google.colab import drive
    IN_COLAB = True
    print("ğŸ” ì½”ë© í™˜ê²½ ê°ì§€ë¨")
except:
    IN_COLAB = False
    print("ğŸ” ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘")

# ê²½ë¡œ ì„¤ì • ë° í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
if IN_COLAB:
    # Google Drive ë§ˆìš´íŠ¸
    try:
        drive.mount('/content/drive')
        print("âœ… Google Drive ë§ˆìš´íŠ¸ ì™„ë£Œ")
    except:
        print("âš ï¸ Google Drive ì´ë¯¸ ë§ˆìš´íŠ¸ë¨")
    
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
    PROJECT_ROOT = "/content/drive/MyDrive/yelp_dataset"
    sys.path.insert(0, PROJECT_ROOT)
    print(f"ğŸ“ í”„ë¡œì íŠ¸ ë£¨íŠ¸: {PROJECT_ROOT}")
    
    DATA_PATH = f"{PROJECT_ROOT}/train"
    MODEL_PATH = f"{PROJECT_ROOT}/models"
else:
    sys.path.append('.')
    DATA_PATH = "data/processed"
    MODEL_PATH = "models"

print(f"ğŸ“‚ ë°ì´í„° ê²½ë¡œ: {DATA_PATH}")
print(f"ğŸ“‚ ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {MODEL_PATH}")

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import numpy as np
from tqdm import tqdm
import matplotlib.pyplot as plt

# ==================== DeepFM ëª¨ë¸ ì •ì˜ ====================
class DeepFM(nn.Module):
    def __init__(self, input_dim, embed_dim=16, hidden_dims=[128, 64, 32]):
        """
        DeepFM ëª¨ë¸
        
        Args:
            input_dim: ì…ë ¥ í”¼ì²˜ ì°¨ì›
            embed_dim: FM ì„ë² ë”© ì°¨ì›
            hidden_dims: Deep ë ˆì´ì–´ ì°¨ì›ë“¤
        """
        super(DeepFM, self).__init__()
        
        self.input_dim = input_dim
        self.embed_dim = embed_dim
        
        # FM Part: 1ì°¨ + 2ì°¨ ìƒí˜¸ì‘ìš©
        self.fm_linear = nn.Linear(input_dim, 1)
        self.fm_embeddings = nn.Linear(input_dim, embed_dim)
        
        # Deep Part: DNN
        deep_layers = []
        prev_dim = input_dim
        for hidden_dim in hidden_dims:
            deep_layers.append(nn.Linear(prev_dim, hidden_dim))
            deep_layers.append(nn.BatchNorm1d(hidden_dim))
            deep_layers.append(nn.ReLU())
            deep_layers.append(nn.Dropout(0.3))
            prev_dim = hidden_dim
        
        self.deep_layers = nn.Sequential(*deep_layers)
        self.final_linear = nn.Linear(prev_dim, 1)
        
    def forward(self, x):
        # FM Part
        fm_linear_part = self.fm_linear(x)
        embeddings = self.fm_embeddings(x)
        sum_of_square = torch.pow(embeddings, 2).sum(dim=1, keepdim=True)
        square_of_sum = torch.pow(embeddings.sum(dim=1, keepdim=True), 2)
        fm_cross_part = 0.5 * (square_of_sum - sum_of_square)
        fm_output = fm_linear_part + fm_cross_part
        
        # Deep Part
        deep_output = self.deep_layers(x)
        deep_output = self.final_linear(deep_output)
        
        # ê²°í•©
        output = fm_output + deep_output
        output = torch.sigmoid(output) * 4 + 1  # [0,1] -> [1,5]
        
        return output.squeeze()

class DeepFMTrainer:
    """DeepFM í•™ìŠµ í´ë˜ìŠ¤"""
    
    def __init__(self, model, device='cpu'):
        self.model = model.to(device)
        self.device = device
        self.criterion = nn.MSELoss()
        self.optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        
    def train_epoch(self, train_loader):
        """1 ì—í­ í•™ìŠµ"""
        self.model.train()
        total_loss = 0
        
        for batch_x, batch_y in train_loader:
            batch_x = batch_x.to(self.device)
            batch_y = batch_y.to(self.device)
            
            predictions = self.model(batch_x)
            loss = self.criterion(predictions, batch_y)
            
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()
            
            total_loss += loss.item()
        
        return total_loss / len(train_loader)
    
    def evaluate(self, val_loader):
        """ê²€ì¦"""
        self.model.eval()
        total_loss = 0
        
        with torch.no_grad():
            for batch_x, batch_y in val_loader:
                batch_x = batch_x.to(self.device)
                batch_y = batch_y.to(self.device)
                
                predictions = self.model(batch_x)
                loss = self.criterion(predictions, batch_y)
                
                total_loss += loss.item()
        
        rmse = (total_loss / len(val_loader)) ** 0.5
        return rmse
    
    def predict(self, x):
        """ì˜ˆì¸¡"""
        self.model.eval()
        with torch.no_grad():
            x = torch.FloatTensor(x).to(self.device)
            predictions = self.model(x)
        return predictions.cpu().numpy()

# ==================== ë°ì´í„°ì…‹ ì •ì˜ ====================
class RankingDataset(Dataset):
    """ë­í‚¹ ë°ì´í„°ì…‹"""
    
    def __init__(self, data_path):
        self.data = pd.read_csv(data_path)
        
        # í”¼ì²˜ì™€ íƒ€ê²Ÿ ë¶„ë¦¬
        feature_cols = [col for col in self.data.columns 
                       if col not in ['user_id', 'business_id', 'avg_stars', 'review_count']]
        
        self.features = self.data[feature_cols].values.astype(np.float32)
        self.targets = self.data['avg_stars'].values.astype(np.float32)
        
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        return self.features[idx], self.targets[idx]

def train_deepfm():
    """DeepFM ëª¨ë¸ í•™ìŠµ"""
    print("=" * 80)
    print("Step 4: DeepFM ëª¨ë¸ í•™ìŠµ")
    print("=" * 80)
    
    # Device ì„¤ì •
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\në””ë°”ì´ìŠ¤: {device}")
    
    # ë°ì´í„° ë¡œë”©
    print("\n[1/5] ë°ì´í„° ë¡œë”© ì¤‘...")
    train_dataset = RankingDataset(f"{DATA_PATH}/ranking_train.csv")
    valid_dataset = RankingDataset(f"{DATA_PATH}/ranking_valid.csv")
    test_dataset = RankingDataset(f"{DATA_PATH}/ranking_test.csv")
    
    print(f"  Train: {len(train_dataset):,}ê°œ")
    print(f"  Valid: {len(valid_dataset):,}ê°œ")
    print(f"  Test:  {len(test_dataset):,}ê°œ")
    print(f"  ì…ë ¥ ì°¨ì›: {train_dataset.features.shape[1]}")
    
    # DataLoader
    batch_size = 512
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    valid_loader = DataLoader(valid_dataset, batch_size=batch_size)
    test_loader = DataLoader(test_dataset, batch_size=batch_size)
    
    # ëª¨ë¸ ìƒì„±
    print("\n[2/5] DeepFM ëª¨ë¸ ìƒì„± ì¤‘...")
    input_dim = train_dataset.features.shape[1]
    print(f"  ì…ë ¥ ì°¨ì›: {input_dim} (User í”¼ì²˜ + Business í”¼ì²˜ + ABSA í”¼ì²˜ + í…ìŠ¤íŠ¸ ì„ë² ë”© 100ì°¨ì›)")
    
    model = DeepFM(
        input_dim=input_dim,
        embed_dim=16,
        hidden_dims=[256, 128, 64]
    )
    
    print(f"  FM ì„ë² ë”© ì°¨ì›: 16")
    print(f"  Deep ë ˆì´ì–´: [256, 128, 64]")
    print(f"  ì´ íŒŒë¼ë¯¸í„°: {sum(p.numel() for p in model.parameters()):,}ê°œ")
    
    # Trainer ìƒì„±
    trainer = DeepFMTrainer(model, device=device)
    
    # í•™ìŠµ
    print("\n[3/5] ëª¨ë¸ í•™ìŠµ ì¤‘...")
    epochs = 20
    best_valid_rmse = float('inf')
    train_losses = []
    valid_rmses = []
    
    for epoch in range(epochs):
        # Train
        train_loss = trainer.train_epoch(train_loader)
        
        # Validation
        valid_rmse = trainer.evaluate(valid_loader)
        
        train_losses.append(train_loss)
        valid_rmses.append(valid_rmse)
        
        print(f"  Epoch {epoch+1:2d}/{epochs} | Train Loss: {train_loss:.4f} | Valid RMSE: {valid_rmse:.4f}")
        
        # Best model ì €ì¥
        if valid_rmse < best_valid_rmse:
            best_valid_rmse = valid_rmse
            os.makedirs(MODEL_PATH, exist_ok=True)
            torch.save(model.state_dict(), f"{MODEL_PATH}/deepfm_ranking.pth")
            print(f"    [BEST] ëª¨ë¸ ì €ì¥!")
    
    # Best model ë¡œë”©
    print("\n[4/5] Best ëª¨ë¸ ë¡œë”© ì¤‘...")
    model.load_state_dict(torch.load(f"{MODEL_PATH}/deepfm_ranking.pth"))
    trainer.model = model.to(device)
    
    # Test í‰ê°€
    print("\n[5/5] Test í‰ê°€ ì¤‘...")
    test_rmse = trainer.evaluate(test_loader)
    print(f"  Test RMSE: {test_rmse:.4f}")
    
    # í•™ìŠµ ê³¡ì„  ì €ì¥
    plt.figure(figsize=(12, 5))
    
    plt.subplot(1, 2, 1)
    plt.plot(train_losses, label='Train Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Training Loss')
    plt.legend()
    plt.grid(True)
    
    plt.subplot(1, 2, 2)
    plt.plot(valid_rmses, label='Valid RMSE')
    plt.xlabel('Epoch')
    plt.ylabel('RMSE')
    plt.title('Validation RMSE')
    plt.legend()
    plt.grid(True)
    
    os.makedirs(MODEL_PATH, exist_ok=True)
    plt.savefig(f"{MODEL_PATH}/deepfm_training_curve.png", dpi=100, bbox_inches='tight')
    print(f"\n  í•™ìŠµ ê³¡ì„  ì €ì¥: {MODEL_PATH}/deepfm_training_curve.png")
    
    # ìƒ˜í”Œ ì˜ˆì¸¡ í™•ì¸
    print("\n  ìƒ˜í”Œ ì˜ˆì¸¡ í™•ì¸ (Test set ì²˜ìŒ 5ê°œ):")
    test_data = pd.read_csv(f"{DATA_PATH}/ranking_test.csv")
    sample_features = test_dataset.features[:5]
    sample_targets = test_dataset.targets[:5]
    predictions = trainer.predict(sample_features)
    
    for i in range(5):
        print(f"    ì‹¤ì œ: {sample_targets[i]:.2f} | ì˜ˆì¸¡: {predictions[i]:.2f} | ì˜¤ì°¨: {abs(sample_targets[i]-predictions[i]):.2f}")
    
    print("\n" + "=" * 80)
    print("[SUCCESS] DeepFM í•™ìŠµ ì™„ë£Œ!")
    print(f"\nBest Valid RMSE: {best_valid_rmse:.4f}")
    print(f"Test RMSE: {test_rmse:.4f}")
    print(f"\nëª¨ë¸ ì €ì¥: {MODEL_PATH}/deepfm_ranking.pth")
    print("ë‹¤ìŒ ë‹¨ê³„: scripts/step5_train_multitower.py ì‹¤í–‰")
    print("=" * 80)

if __name__ == "__main__":
    train_deepfm()

