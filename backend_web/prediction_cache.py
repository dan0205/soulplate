"""
ì‚¬ìš©ìž-ìŒì‹ì  ì˜ˆì¸¡ ì ìˆ˜ ìºì‹± ì„œë¹„ìŠ¤
"""

import logging
import httpx
import os
from datetime import datetime, timezone
from sqlalchemy.orm import Session
from sqlalchemy import and_

import models

logger = logging.getLogger(__name__)

# AI ëª¨ë¸ ì„œë²„ URL
MODEL_SERVER_URL = os.getenv("MODEL_API_URL", "https://backendmodel-production-77a7.up.railway.app")


async def calculate_and_store_predictions(user_id: int, db: Session):
    """
    íŠ¹ì • ì‚¬ìš©ìžì˜ ëª¨ë“  ìŒì‹ì ì— ëŒ€í•œ ì˜ˆì¸¡ ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ê³  DBì— ì €ìž¥
    
    Args:
        user_id: ì‚¬ìš©ìž ID
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
    """
    import time
    
    total_start_time = time.time()
    logger.info(f"ðŸ”® [Prediction Cache] ì‚¬ìš©ìž {user_id}ì˜ ì˜ˆì¸¡ ê³„ì‚° ì‹œìž‘")
    
    try:
        # 1. ì‚¬ìš©ìž ì •ë³´ ì¡°íšŒ
        user = db.query(models.User).filter(models.User.id == user_id).first()
        if not user:
            logger.error(f"âŒ [Prediction Cache] ì‚¬ìš©ìž {user_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return
        
        # 2. ëª¨ë“  ìŒì‹ì  ì¡°íšŒ
        businesses = db.query(models.Business).all()
        total_businesses = len(businesses)
        logger.info(f"ðŸ“Š [Prediction Cache] {total_businesses}ê°œ ìŒì‹ì ì— ëŒ€í•´ ì˜ˆì¸¡ ê³„ì‚° ì¤‘ (timeout=120s per request)...")
        
        # 3. ê° ìŒì‹ì ì— ëŒ€í•´ ì˜ˆì¸¡ ìš”ì²­
        calculated_at = datetime.now(timezone.utc)
        success_count = 0
        error_count = 0
        timeout_count = 0
        
        # ì‹œê°„ ì¸¡ì •ì„ ìœ„í•œ ë³€ìˆ˜ë“¤
        api_call_times = []
        slow_businesses = []  # 3ì´ˆ ì´ìƒ ê±¸ë¦° ìš”ì²­ë“¤ ì¶”ì 
        
        async with httpx.AsyncClient(timeout=120.0) as client:
            for idx, business in enumerate(businesses, 1):
                try:
                    # ì§„í–‰ìƒí™© ë¡œê·¸ (10ê°œë§ˆë‹¤)
                    if idx % 10 == 0 or idx == 1:
                        logger.info(f"  ðŸ“ˆ ì§„í–‰ì¤‘: {idx}/{total_businesses} ({(idx/total_businesses*100):.1f}%)")
                    
                    # AI ëª¨ë¸ ì„œë²„ì— ì˜ˆì¸¡ ìš”ì²­
                    request_start = time.time()
                    
                    response = await client.post(
                        f"{MODEL_SERVER_URL}/predict_rating",
                        json={
                            "user_data": {
                                "review_count": user.review_count,
                                "useful": user.useful,
                                "compliment": user.compliment,
                                "fans": user.fans,
                                "average_stars": user.average_stars,
                                "yelping_since_days": user.yelping_since_days,
                                "absa_features": user.absa_features or {}
                            },
                            "business_data": {
                                "stars": business.stars,
                                "review_count": business.review_count,
                                "latitude": business.latitude,
                                "longitude": business.longitude,
                                "absa_features": business.absa_features or {}
                            }
                        }
                    )
                    
                    request_time = time.time() - request_start
                    api_call_times.append(request_time)
                    
                    # ëŠë¦° ìš”ì²­ ì¶”ì  (3ì´ˆ ì´ìƒ)
                    if request_time > 3.0:
                        slow_businesses.append({
                            "id": business.id,
                            "name": business.name or f"Business {business.id}",
                            "time": request_time
                        })
                    
                    if response.status_code == 200:
                        data = response.json()
                        deepfm_score = data.get("deepfm_rating", 3.0)
                        multitower_score = data.get("multitower_rating", 3.0)
                        
                        # DBì— ì €ìž¥ (UPSERT)
                        existing = db.query(models.UserBusinessPrediction).filter(
                            and_(
                                models.UserBusinessPrediction.user_id == user_id,
                                models.UserBusinessPrediction.business_id == business.id
                            )
                        ).first()
                        
                        if existing:
                            # ì—…ë°ì´íŠ¸
                            existing.deepfm_score = deepfm_score
                            existing.multitower_score = multitower_score
                            existing.is_stale = False
                            existing.calculated_at = calculated_at
                        else:
                            # ì‹ ê·œ ì‚½ìž…
                            prediction = models.UserBusinessPrediction(
                                user_id=user_id,
                                business_id=business.id,
                                deepfm_score=deepfm_score,
                                multitower_score=multitower_score,
                                is_stale=False,
                                calculated_at=calculated_at
                            )
                            db.add(prediction)
                        
                        success_count += 1
                    else:
                        logger.warning(f"âš ï¸  [Prediction Cache] ìŒì‹ì  {business.id} ì˜ˆì¸¡ ì‹¤íŒ¨: HTTP {response.status_code} (ì†Œìš”: {request_time:.2f}s)")
                        error_count += 1
                
                except httpx.TimeoutException:
                    request_time = time.time() - request_start
                    logger.error(f"â±ï¸  [Prediction Cache] ìŒì‹ì  {business.id} íƒ€ìž„ì•„ì›ƒ (120ì´ˆ ì´ˆê³¼, ì‹¤ì œ: {request_time:.2f}s)")
                    timeout_count += 1
                    error_count += 1
                
                except Exception as e:
                    request_time = time.time() - request_start
                    logger.error(f"âŒ [Prediction Cache] ìŒì‹ì  {business.id} ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ (ì†Œìš”: {request_time:.2f}s): {e}")
                    error_count += 1
            
            # 4. DB ì»¤ë°‹
            commit_start = time.time()
            db.commit()
            commit_time = time.time() - commit_start
            
            # 5. ìµœì¢… í†µê³„ ê³„ì‚°
            total_time = time.time() - total_start_time
            
            # API í˜¸ì¶œ ì‹œê°„ í†µê³„
            if api_call_times:
                avg_time = sum(api_call_times) / len(api_call_times)
                min_time = min(api_call_times)
                max_time = max(api_call_times)
            else:
                avg_time = min_time = max_time = 0
            
            # ìµœì¢… ë¡œê·¸
            logger.info(f"âœ… [Prediction Cache] ì™„ë£Œ - ì´ ì†Œìš”ì‹œê°„: {total_time:.2f}s")
            logger.info(f"   ðŸ“Š ê²°ê³¼: ì„±ê³µ {success_count}, ì‹¤íŒ¨ {error_count} (íƒ€ìž„ì•„ì›ƒ: {timeout_count})")
            logger.info(f"   â±ï¸  API í˜¸ì¶œ ì‹œê°„: í‰ê·  {avg_time:.2f}s, ìµœì†Œ {min_time:.2f}s, ìµœëŒ€ {max_time:.2f}s")
            logger.info(f"   ðŸ’¾ DB ì»¤ë°‹ ì‹œê°„: {commit_time:.2f}s")
            
            # ëŠë¦° ìš”ì²­ë“¤ ë¡œê·¸
            if slow_businesses:
                logger.warning(f"   âš ï¸  ëŠë¦° ìš”ì²­ (3ì´ˆ ì´ìƒ): {len(slow_businesses)}ê°œ")
                for slow in slow_businesses[:5]:  # ìƒìœ„ 5ê°œë§Œ í‘œì‹œ
                    logger.warning(f"      - {slow['name']} (ID: {slow['id']}): {slow['time']:.2f}s")
    
    except Exception as e:
        total_time = time.time() - total_start_time
        logger.error(f"âŒ [Prediction Cache] ì‚¬ìš©ìž {user_id} ì˜ˆì¸¡ ê³„ì‚° ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜ (ì†Œìš”: {total_time:.2f}s): {e}")
        import traceback
        traceback.print_exc()
        db.rollback()


def mark_predictions_stale(user_id: int, db: Session):
    """
    ì‚¬ìš©ìžì˜ ëª¨ë“  ì˜ˆì¸¡ì„ ìž¬ê³„ì‚° í•„ìš” ìƒíƒœë¡œ í‘œì‹œ
    
    Args:
        user_id: ì‚¬ìš©ìž ID
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
    """
    logger.info(f"[Prediction Cache] ì‚¬ìš©ìž {user_id}ì˜ ì˜ˆì¸¡ì„ staleë¡œ í‘œì‹œ")
    
    try:
        updated_count = db.query(models.UserBusinessPrediction).filter(
            models.UserBusinessPrediction.user_id == user_id
        ).update({"is_stale": True})
        
        db.commit()
        logger.info(f"[Prediction Cache] {updated_count}ê°œ ì˜ˆì¸¡ì„ staleë¡œ í‘œì‹œ ì™„ë£Œ")
    
    except Exception as e:
        logger.error(f"[Prediction Cache] stale í‘œì‹œ ì¤‘ ì˜¤ë¥˜: {e}")
        db.rollback()


def get_cached_predictions(user_id: int, business_ids: list, db: Session) -> dict:
    """
    ìºì‹œëœ ì˜ˆì¸¡ê°’ì„ ì¡°íšŒ
    
    Args:
        user_id: ì‚¬ìš©ìž ID
        business_ids: ì¡°íšŒí•  ìŒì‹ì  ID ë¦¬ìŠ¤íŠ¸
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
    
    Returns:
        {business_id: {"deepfm": score, "multitower": score, "is_stale": bool}}
    """
    predictions = db.query(models.UserBusinessPrediction).filter(
        and_(
            models.UserBusinessPrediction.user_id == user_id,
            models.UserBusinessPrediction.business_id.in_(business_ids)
        )
    ).all()
    
    result = {}
    for pred in predictions:
        result[pred.business_id] = {
            "deepfm": pred.deepfm_score,
            "multitower": pred.multitower_score,
            "is_stale": pred.is_stale
        }
    
    return result


def check_predictions_exist(user_id: int, db: Session) -> bool:
    """
    ì‚¬ìš©ìžì˜ ì˜ˆì¸¡ê°’ì´ ì¡´ìž¬í•˜ëŠ”ì§€ í™•ì¸
    
    Args:
        user_id: ì‚¬ìš©ìž ID
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
    
    Returns:
        bool: ì˜ˆì¸¡ê°’ ì¡´ìž¬ ì—¬ë¶€
    """
    count = db.query(models.UserBusinessPrediction).filter(
        models.UserBusinessPrediction.user_id == user_id
    ).count()
    
    return count > 0

