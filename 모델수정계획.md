추천 시스템 아키텍처 및 모델 명세서

1. 프로젝트 목표

"리뷰" 단위의 별점을 예측하는 것이 아닌, "사용자"에게 "가게(비즈니스)"를 추천하는 개인화 추천 시스템을 구축한다. 최종 출력은 사용자가 좋아할 만한 가게(Item)의 Top-K 리스트이다.

2. 보유 자산 (Current Assets)

ABSA 모델 (lmkor-bert v2): 개별 리뷰 텍스트를 입력받아, (속성, 감성) (예: 음식-긍정, 가격-부정)을 추출하는 고성능 피처 추출기.

리뷰 단위 별점 예측 모델 (DeepFM / Multi-Tower v1):

입력: (User, Item, Review_Text, Review_ABSA)

출력: (Review_Rating) (단일 리뷰의 예상 별점)

참고: 이 모델은 "가게 추천"에 직접 사용할 수 없으나, 아키텍처와 ABSA 피처의 유효성을 증명함.

데이터: 사용자 정보, 가게 정보, 사용자가 가게에 작성한 리뷰(stars 포함) 전체 이력.

3. 핵심 판단: Two-Tower (Retrieval)의 필요성

결론: Two-Tower (Retrieval) + FAISS 아키텍처는 사용하지 않는다. (폐기)

이유: 전체 추천 대상 가게(아이템) 수가 200개 미만으로 매우 적다. 100만 개 중 200개를 거르는 '후보군 선별(Retrieval)' 단계는 아이템 수가 극도로 많을 때(> 50,000) 의미가 있으며, 현 상황에서는 불필요한 복잡성이다.

4. 최종 채택 아키텍처: 단일 랭킹 모델 (Single-Stage Ranking)

아이템 수가 매우 적으므로, **모든 가게(약 200개)**에 대해 "사용자와의 궁합 점수(예상 별점)"를 계산하는 것이 실시간 API 응답 시간(예: < 1초) 내에 충분히 가능하다.

따라서, DeepFM (또는 Multi-Tower) 아키텍처를 "가게 추천" 용도로 새롭게 학습시켜 단일 랭킹 모델로 사용한다.

5. 랭킹 모델 (DeepFM_v2) 명세

5.1. 모델 목표

DeepFM_v2(User_Input_Vector, Item_Input_Vector) → Predicted_Business_Rating

사용자 정보와 가게 정보를 입력받아, 해당 사용자가 해당 가게에 매길 "가게(Business) 단위의 예상 별점" (실수 값)을 예측하는 회귀(Regression) 모델을 학습한다.

5.2. 출력 (정답) 데이터 (Y) : true_rating

모델이 맞춰야 할 정답(Y)은 "가게의 전체 평균 별점"이 아니다.
**"특정 사용자(User)가 특정 가게(Item)에 역사적으로 매긴 실제 별점들의 평균"**이다.

생성 방법: reviews 테이블을 user_id, business_id로 GROUP BY한 뒤, AVG(stars)를 계산하여 생성한다.

예시:
| user_id | business_id | Y_true_rating |
| :--- | :--- | :--- |
| user_A | item_B | 4.0 |
| user_B | item_B | 2.0 |

5.3. 입력 데이터 (X) : 집계된 피처 벡터

실시간 추천 시점에는 "리뷰 텍스트"라는 입력이 존재하지 않는다. 따라서 "리뷰"에서 파생된 정보는 "집계된(Aggregated)" 피처로 미리 계산하여 사용한다.

[ A. X_user (사용자 측 입력 벡터) ]

User ID: 모델 내부의 Embedding 레이어 입력.

User 기본 피처: age, gender, total_review_count 등.

[핵심] User 집계 ABSA 피처:

소스: 해당 사용자가 과거에 작성한 모든 리뷰.

처리: 보유한 ABSA 모델을 모든 리뷰에 실행 후, 사용자 단위로 집계.

예시: user_food_pos_ratio (음식 긍정 비율), user_price_sensitivity (가격 언급 빈도), user_service_avg_sentiment (서비스 평균 감성) 등 N차원 벡터.

[ B. X_item (아이템 측 입력 벡터) ]

Item ID: 모델 내부의 Embedding 레이어 입력.

Item 기본 피처: category, global_avg_stars, total_review_count 등.

[핵심] Item 집계 ABSA 피처:

소스: 해당 가게에 달려있는 모든 리뷰.

처리: ABSA 모델을 모든 리뷰에 실행 후, 가게 단위로 집계.

예시: item_food_pos_ratio (음식 긍정 비율), item_service_neg_count (서비스 부정 언급 수) 등 M차원 벡터.

6. API 서빙 워크플로우 (Inference)

사용자(User_A)가 추천을 요청한다.

서버는 User_A의 X_user 피처 벡터를 준비한다.

서버는 **전체 가게 목록(약 200개)**을 DB에서 가져온다.

for 루프를 200번 실행한다:

Item_B의 X_item 피처 벡터를 가져온다.

DeepFM_v2(X_user, X_item_B) → 예측 4.8점

DeepFM_v2(X_user, X_item_C) → 예측 3.5점

...

200개의 "예상 가게 별점" 리스트를 얻는다.

이 점수를 sort (내림차순)하여 Top-K개의 business_id를 사용자에게 반환한다.

7. 결론 및 제안 (LLM에 대한 질문)

질문: 원래의 two_tower.py (Two-Tower 모델)를 수정해야 하는가?

답변: 아니요. 수정이 아니라 폐기(Discard)해야 합니다.

사유: 전체 아이템 수가 매우 적어, 1단계 Retrieval(후보 선별) 모델 자체가 필요하지 않습니다. Two-Tower 아키텍처는 이 문제에 과적합(Overkill)되며 비효율적입니다.

권장 사항: DeepFM 또는 Multi-Tower 아키텍처를 기반으로, "5. 모델 명세" 섹션에 기술된 **"가게 단위"**의 입력(X)과 출력(Y)을 사용하도록 새로운 랭킹 모델을 학습해야 합니다.